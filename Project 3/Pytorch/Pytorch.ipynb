{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the mean and std of images in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 432\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchmetrics\n",
    "from torch import nn, optim\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import random_split\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pathlib import Path as p\n",
    "import re\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "from ../Preprocessing_zip import Processor\n",
    "\n",
    "NUM_WORKERS = os.cpu_count() // 2\n",
    "\n",
    "# data_path = './Hand extraction/source_box'\n",
    "# transform_img = transforms.Compose(\n",
    "#     [transforms.CenterCrop(720),\n",
    "#      transforms.ToTensor()]\n",
    "# )\n",
    "#\n",
    "# image_data = ImageFolder(\n",
    "#     root=data_path, transform=transform_img\n",
    "# )\n",
    "# # data_processor = Processor(data_path, transforms=transform_img, data_sample=0.5)\n",
    "# # data_processor.get_data()\n",
    "# # train_image_data = data_processor.train\n",
    "#\n",
    "# image_data_loader = DataLoader(\n",
    "#     image_data,\n",
    "#     batch_size=len(image_data),\n",
    "#     shuffle=False,\n",
    "#     num_workers=NUM_WORKERS)\n",
    "#\n",
    "#\n",
    "# def mean_std(loader):\n",
    "#     images, _ = next(iter(loader))\n",
    "#     # shape of images = [b,c,w,h]\n",
    "#     mean, std = images.mean([0, 2, 3]), images.std([0, 2, 3])\n",
    "#     return mean, std\n",
    "#\n",
    "#\n",
    "# IMAGES_MEAN, IMAGES_STD = mean_std(image_data_loader)\n",
    "\n",
    "BATCH_SIZE = int(2 ** 6)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "pl.seed_everything(432)\n",
    "IMAGES_MEAN, IMAGES_STD = torch.tensor([0.0784, 0.0672, 0.0628]), torch.tensor([0.2256, 0.1979, 0.1872])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lightning Data Module (subclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = None, batch_size: int = BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir or os.getcwd()\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.train_transform = transforms.Compose(\n",
    "            [transforms.CenterCrop(200),\n",
    "             transforms.RandomHorizontalFlip(p=0.1),\n",
    "             transforms.RandomVerticalFlip(p=0.1),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize(IMAGES_MEAN, IMAGES_STD)]\n",
    "        )\n",
    "        self.test_transform = transforms.Compose(\n",
    "            [transforms.Grayscale(num_output_channels=1),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize(IMAGES_MEAN, IMAGES_STD)]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.data = ImageFolder(\n",
    "            self.data_dir, transform=self.train_transform)\n",
    "\n",
    "    def setup(self, train_ratio: float = 0.9, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            train_amount = int(len(self.data) * train_ratio)\n",
    "            self.train, self.test = random_split(\n",
    "                self.data, [train_amount, len(self.data) - train_amount])\n",
    "            train_amount = int(len(self.train) * train_ratio)\n",
    "            self.train, self.val = random_split(\n",
    "                self.train, [train_amount, len(self.train) - train_amount])\n",
    "        if stage == 'test' or stage is None:\n",
    "            pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=True,\n",
    "                          shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=True)\n",
    "\n",
    "    def smallest_size(self):\n",
    "        '''Return the smallest resolution of images in the folder_path'''\n",
    "        min_size = 10 ** 9\n",
    "        for file in p(self.data_dir).rglob('*'):\n",
    "            if file.is_file():\n",
    "                im = Image.open(file)\n",
    "                min_size = min(min_size, *im.size)\n",
    "        return min_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lightning Module subclass (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We inherit a Resnet model\n",
    "https://github.com/Stevellen/ResNet-Lightning/blob/master/resnet_classifier.py\n",
    "https://jarvislabs.ai/blogs/resnet/\n",
    "https://discuss.pytorch.org/t/transfer-learning-usage-with-different-input-size/20744/3\n",
    "'''\n",
    "\n",
    "\n",
    "class Resnet(pl.LightningModule):\n",
    "    def __init__(self, num_classes=10, model_choice=18, weights=None):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(locals())\n",
    "        model_choices = {\n",
    "            18: models.resnet18, 34: models.resnet34,\n",
    "            50: models.resnet50, 101: models.resnet101,\n",
    "            152: models.resnet152,\n",
    "            'vgg16': models.vgg16\n",
    "        }\n",
    "        self.acc = torchmetrics.Accuracy()\n",
    "        self.lr = 1e-3\n",
    "        # instantiate loss criterion\n",
    "        self.loss = nn.BCEWithLogitsLoss() if num_classes == 2 else nn.CrossEntropyLoss()\n",
    "        # Do not use a pretrained ResNet backbone\n",
    "        self.model = model_choices[model_choice](weights=weights)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self.forward(x)\n",
    "        if self.num_classes == 2:\n",
    "            y = F.one_hot(y, num_classes=2).float()\n",
    "        loss = self.loss(preds, y)\n",
    "        acc = self.acc(preds, y)\n",
    "        # Logging the loss\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, on_step=True, logger=True)\n",
    "        self.log('train_acc', acc, on_epoch=True, on_step=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self.forward(x)\n",
    "        if self.num_classes == 2:\n",
    "            y = F.one_hot(y, num_classes=2).float()\n",
    "        loss = self.loss(preds, y)\n",
    "        acc = self.acc(preds, y)\n",
    "        # Logging the loss\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=True, logger=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, on_step=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        if self.num_classes == 2:\n",
    "            y = F.one_hot(y, num_classes=2).float()\n",
    "        loss = self.loss(preds, y)\n",
    "        acc = self.acc(preds, y)\n",
    "        # perform logging\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, on_step=True, logger=True)\n",
    "        self.log(\"test_acc\", acc, on_epoch=True, on_step=True, logger=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def find_best_checkpoint(cp_path) -> (str, int):\n",
    "    '''Returns the best checkpoint file with the number of cumulative epoch'''\n",
    "    if next(p(cp_path).iterdir(), None) is None:\n",
    "        return None, 0\n",
    "    acc_pattern = re.compile(r'(?<=val_loss\\=)\\d.\\d{2}')\n",
    "    cps = [str(cp) for cp in p(cp_path).glob('*')]\n",
    "    cps = sorted(cps, key=lambda line: re.search(acc_pattern, line).group())\n",
    "    best = cps[0]\n",
    "    resumed_epoch = re.search('\\d+', best.split(',', 1)[0]).group()\n",
    "    with open(f'{p(cp_path) / \"Resumed epoch.txt\"}', 'w') as f:\n",
    "        f.write(resumed_epoch)\n",
    "    return best, int(resumed_epoch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resumed_epoch = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | acc   | Accuracy         | 0     \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "2 | model | ResNet           | 11.7 M\n",
      "-------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "23.379    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b3fbb77b382414a9aed15c2b34da274"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dtngh\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "C:\\Users\\dtngh\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "C:\\Users\\dtngh\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1562: PossibleUserWarning: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22e2d4ef9f1f48d4b60149aed888f7c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78824a2a7c1a4d79a63913e209c5c8e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7338563276749558d865c23b777ac5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53f8c737adda4181958da863bad84406"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8df4f29221a14ebc979d5f9cf4137107"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff3691147b814480bf0f828cdefe175a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99f78d5420db4de7afd4a8d4a7659058"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67a10231fbf94046a2952a688d5bcd05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14ccd08007ec4130b63fd71e0edb66c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32709154418a4e30a6953ed555eb70c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7861638f00842ea82abab503d52175f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84e285fc194c467595a286dc1d0929fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3eabc72fd064e068682b3f1a73b7bfa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e64339e195c8461487308ebff3893d69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddabefb42f52471a9340b6a91a42fccc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcc7676a6c6c469eb8f93515aee6e3bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26675fb76ccf43469821b6b495138a51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e428965a55004f218667b73959e9bce1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34e2f466ee4b40b483e58748937448ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "321635fd181d434bb6ca628cb636c4db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8136e3c484342198d2a12ab66bfae02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "471a8be176554655a62a66e992b915dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aab2878f70734643b17f021afa16a0dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1511b603a0e241cd8192044b33b5c8fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be710f35bf6c409baba199476e71298d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dtngh\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "data_path = \"Hand extraction/source_box\"\n",
    "model_cp_path = \"Model Checkpoints\"\n",
    "model_cp_filename = \"Image_model\"\n",
    "data_module = ImageDataset(data_path)\n",
    "check_point_frequency = 10\n",
    "best_cpt, resumed_epoch = find_best_checkpoint(model_cp_path)\n",
    "print(f'resumed_epoch = {resumed_epoch}')\n",
    "checkpoint_params = {'filename': '{epoch}, {val_loss:.2f}, {val_acc:.2f}', 'save_top_k': 5,\n",
    "                     'monitor': \"val_acc\",\n",
    "                     'mode': 'max',\n",
    "                     'every_n_epochs': check_point_frequency, 'save_on_train_epoch_end': True}\n",
    "model = Resnet()\n",
    "if best_cpt:\n",
    "    model = Resnet.load_from_checkpoint(best_cpt)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=500 - resumed_epoch,\n",
    "    auto_lr_find=True,\n",
    "    accelerator='gpu',\n",
    "    devices=-1,\n",
    "    auto_select_gpus=True,\n",
    "    auto_scale_batch_size='binsearch',\n",
    "    check_val_every_n_epoch=check_point_frequency,\n",
    "    detect_anomaly=True,\n",
    "    precision=16,\n",
    "    callbacks=ModelCheckpoint(dirpath=model_cp_path, **checkpoint_params),\n",
    ")\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "import webbrowser\n",
    "\n",
    "# Open a url after done\n",
    "webbrowser.open('https://youtu.be/5dwxGvmUG90?t=53')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "1190"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"shutdown /s /t 1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f8d4f4cc8fa12dbb26313d8b3e110534f25fd535deed971b5eaf97b1f1a75b3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
